{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdd87cd",
   "metadata": {},
   "source": [
    "# **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3716c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:               2.7.1+cu118\n",
      "device:              cuda\n",
      "numpy:               2.2.4\n",
      "matplotlib:          3.10.3\n",
      "logger (custom):     loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(f\"{'torch:':<20} {torch.__version__}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{'device:':<20} {device}\")\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "print(f\"{'numpy:':<20} {np.__version__}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"{'matplotlib:':<20} {plt.matplotlib.__version__}\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logger\n",
    "print(f\"{'logger (custom):':<20} loaded\")\n",
    "\n",
    "from Models.Architectures.edgeGNN import EdgeCentricNetworkStatic\n",
    "from DataManagement.data import financialDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a61e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Sector-Based Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\DataManagement\\data_load.py:38: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  sector_data = yf.download(tickers=list(sector_mapping.keys()), start=start_date, end=end_date)\n",
      "[*********************100%***********************]  11 of 11 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded yfinance sector data for =:\n",
      "-> Keys: ['XLK', 'XLF', 'XLE', 'XLV', 'XLI', 'XLP', 'XLY', 'XLU', 'XLB', 'XLRE', 'XLC']\n",
      "-> Values: listdict_values(['Technology', 'Financials', 'Energy', 'Health Care', 'Industrials', 'Consumer Staples', 'Consumer Discretionary', 'Utilities', 'Materials', 'Real Estate', 'Communication Services'])\n",
      "Flattening Column Labels to Remove Tuple-Based Column Structure... & Shifting Date into Column\n",
      "* Done Preprocessing and Organizing Data *\n",
      "\n",
      "=== Checking Download Uniformity ===\n",
      "XLK: 1254 rows with data\n",
      "XLF: 1254 rows with data\n",
      "XLE: 1254 rows with data\n",
      "XLV: 1254 rows with data\n",
      "XLI: 1254 rows with data\n",
      "XLP: 1254 rows with data\n",
      "XLY: 1254 rows with data\n",
      "XLU: 1254 rows with data\n",
      "XLB: 1254 rows with data\n",
      "XLRE: 1254 rows with data\n",
      "XLC: 1254 rows with data\n",
      "âœ“ All sectors have same number of dates\n",
      "Common dates: 1254\n",
      "XLK len: 1254\n",
      "XLF len: 1254\n",
      "XLE len: 1254\n",
      "XLV len: 1254\n",
      "XLI len: 1254\n",
      "XLP len: 1254\n",
      "XLY len: 1254\n",
      "XLU len: 1254\n",
      "XLB len: 1254\n",
      "XLRE len: 1254\n",
      "XLC len: 1254\n",
      "XLK data length: 1223\n",
      "XLF data length: 1223\n",
      "XLE data length: 1223\n",
      "XLV data length: 1223\n",
      "XLI data length: 1223\n",
      "XLP data length: 1223\n",
      "XLY data length: 1223\n",
      "XLU data length: 1223\n",
      "XLB data length: 1223\n",
      "XLRE data length: 1223\n",
      "XLC data length: 1223\n",
      "XLK len: 1223\n",
      "XLF len: 1223\n",
      "XLE len: 1223\n",
      "XLV len: 1223\n",
      "XLI len: 1223\n",
      "XLP len: 1223\n",
      "XLY len: 1223\n",
      "XLU len: 1223\n",
      "XLB len: 1223\n",
      "XLRE len: 1223\n",
      "XLC len: 1223\n",
      "Any NaNs in features? tensor(False)\n",
      "Any Infs in features? tensor(False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\DataManagement\\data.py:74: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  feature_data = torch.tensor(data=feature_data, dtype=torch.float32).transpose(0, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = financialDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be74c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Feature Dim: torch.Size([64, 11, 89])\n",
      "Batch Target Dim: torch.Size([64, 11])\n",
      "Test Dataset Length: 245\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(dataset)\n",
    "\n",
    "train_split = 0.8\n",
    "test_split = 0.2\n",
    "\n",
    "train_size = int(train_split * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "\n",
    "test_dataset = torch.utils.data.Subset(dataset, list(range(train_size, num_samples)))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "sample_batch = next(iter(test_loader))\n",
    "print(f\"Batch Feature Dim: {sample_batch[0].shape}\")\n",
    "print(f\"Batch Target Dim: {sample_batch[1].shape}\")\n",
    "print(f\"Test Dataset Length: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f5dd148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeCentricNetwork(\n",
       "  (edge_updater): Sequential(\n",
       "    (0): Linear(in_features=178, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       "  (regression): Sequential(\n",
       "    (0): Linear(in_features=110, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EdgeCentricNetwork(num_nodes=sample_batch[0].shape[1], directed=True, edge_dim=10, node_dim=sample_batch[0].shape[2])\n",
    "model.load_state_dict(state_dict=torch.load(\"Models/save/DenseEdgeCentricGNN_state.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2012bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48b81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:128: UserWarning: Using a target size (torch.Size([64, 11])) that is different to the input size (torch.Size([64, 11, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:128: UserWarning: Using a target size (torch.Size([53, 11])) that is different to the input size (torch.Size([53, 11, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Loss: 0.7987518757581711\n",
      "Number of Test Samples: 245.0\n",
      "Average Loss: 0.0032602117377884534\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "evaluation_losses = []\n",
    "num_samples = 0.0\n",
    "\n",
    "for features, targets in test_loader:\n",
    "    features, targets = features.to(device), targets.to(device)\n",
    "    num_samples += features.size(0)\n",
    "    output = model(features).unsqueeze(2)\n",
    "    \n",
    "    loss = criterion(output, targets)\n",
    "\n",
    "    evaluation_losses.append(loss.item())\n",
    "\n",
    "evaluation_losses = np.array(evaluation_losses)\n",
    "total_loss = evaluation_losses.sum()\n",
    "\n",
    "print(f\"Total Loss: {total_loss}\")\n",
    "print(f\"Number of Test Samples: {num_samples}\")\n",
    "print(f\"Average Loss: {total_loss / num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63c8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
