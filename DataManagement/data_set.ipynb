{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026d7a27",
   "metadata": {},
   "source": [
    "# **Data Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62abbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClaim: Develop some system that when backtracking produces substantial Alpha by exploiting hidden market trends\\n    Method: We will be conducting Sector Research, and we will attempt to generate some level of predicted alpha, or even some trend prediction\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\"\"\"\n",
    "Claim: Develop some system that when backtracking produces substantial Alpha by exploiting hidden market trends\n",
    "    Method: We will be conducting Sector Research, and we will attempt to generate some level of predicted alpha, or even some trend prediction\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7b1d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'XLK', 1: 'XLF', 2: 'XLE', 3: 'XLV', 4: 'XLI', 5: 'XLP', 6: 'XLY', 7: 'XLU', 8: 'XLB', 9: 'XLRE', 10: 'XLC'}\n"
     ]
    }
   ],
   "source": [
    "# Sector Conversion Map\n",
    "sector_mapping = {\n",
    "        'XLK': 'Technology',\n",
    "        'XLF': 'Financials', \n",
    "        'XLE': 'Energy',\n",
    "        'XLV': 'Health Care',\n",
    "        'XLI': 'Industrials',\n",
    "        'XLP': 'Consumer Staples',\n",
    "        'XLY': 'Consumer Discretionary',\n",
    "        'XLU': 'Utilities',\n",
    "        'XLB': 'Materials',\n",
    "        'XLRE': 'Real Estate',\n",
    "        'XLC': 'Communication Services'\n",
    "    }\n",
    "\n",
    "node_mapping = {}\n",
    "\n",
    "for i, key in enumerate(sector_mapping.keys()):\n",
    "    node_mapping[i] = key\n",
    "\n",
    "print(node_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103bf28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Sector-Based Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lordw\\AppData\\Local\\Temp\\ipykernel_37208\\3059118914.py:7: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  sector_data = yf.download(tickers=list(sector_mapping.keys()), start=start_date, end=end_date)\n",
      "[*********************100%***********************]  11 of 11 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded yfinance sector data for =:\n",
      "-> Keys: ['XLK', 'XLF', 'XLE', 'XLV', 'XLI', 'XLP', 'XLY', 'XLU', 'XLB', 'XLRE', 'XLC']\n",
      "-> Values: listdict_values(['Technology', 'Financials', 'Energy', 'Health Care', 'Industrials', 'Consumer Staples', 'Consumer Discretionary', 'Utilities', 'Materials', 'Real Estate', 'Communication Services'])\n",
      "Flattening Column Labels to Remove Tuple-Based Column Structure... & Shifting Date into Column\n",
      "* Done Preprocessing and Organizing Data *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>XLB_Close</th>\n",
       "      <th>XLC_Close</th>\n",
       "      <th>XLE_Close</th>\n",
       "      <th>XLF_Close</th>\n",
       "      <th>XLI_Close</th>\n",
       "      <th>XLK_Close</th>\n",
       "      <th>XLP_Close</th>\n",
       "      <th>XLRE_Close</th>\n",
       "      <th>XLU_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>XLC_Volume</th>\n",
       "      <th>XLE_Volume</th>\n",
       "      <th>XLF_Volume</th>\n",
       "      <th>XLI_Volume</th>\n",
       "      <th>XLK_Volume</th>\n",
       "      <th>XLP_Volume</th>\n",
       "      <th>XLRE_Volume</th>\n",
       "      <th>XLU_Volume</th>\n",
       "      <th>XLV_Volume</th>\n",
       "      <th>XLY_Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>54.920506</td>\n",
       "      <td>54.941647</td>\n",
       "      <td>30.416573</td>\n",
       "      <td>22.060677</td>\n",
       "      <td>66.268852</td>\n",
       "      <td>102.061813</td>\n",
       "      <td>53.747543</td>\n",
       "      <td>29.181149</td>\n",
       "      <td>50.420036</td>\n",
       "      <td>...</td>\n",
       "      <td>2216700</td>\n",
       "      <td>18822800</td>\n",
       "      <td>74678500</td>\n",
       "      <td>13017100</td>\n",
       "      <td>8590300</td>\n",
       "      <td>7770200</td>\n",
       "      <td>3339300</td>\n",
       "      <td>15063200</td>\n",
       "      <td>6412200</td>\n",
       "      <td>3024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>55.382324</td>\n",
       "      <td>54.817520</td>\n",
       "      <td>29.991512</td>\n",
       "      <td>21.877981</td>\n",
       "      <td>66.667023</td>\n",
       "      <td>102.561005</td>\n",
       "      <td>54.037067</td>\n",
       "      <td>29.586670</td>\n",
       "      <td>51.558929</td>\n",
       "      <td>...</td>\n",
       "      <td>1928900</td>\n",
       "      <td>17716900</td>\n",
       "      <td>47033200</td>\n",
       "      <td>8605200</td>\n",
       "      <td>6355200</td>\n",
       "      <td>6321700</td>\n",
       "      <td>8696300</td>\n",
       "      <td>22950800</td>\n",
       "      <td>7548600</td>\n",
       "      <td>3094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>54.902401</td>\n",
       "      <td>55.476357</td>\n",
       "      <td>29.492876</td>\n",
       "      <td>21.777494</td>\n",
       "      <td>65.852211</td>\n",
       "      <td>105.181931</td>\n",
       "      <td>53.493111</td>\n",
       "      <td>29.307875</td>\n",
       "      <td>50.882427</td>\n",
       "      <td>...</td>\n",
       "      <td>2205300</td>\n",
       "      <td>20076500</td>\n",
       "      <td>40127600</td>\n",
       "      <td>9404600</td>\n",
       "      <td>8509200</td>\n",
       "      <td>6818600</td>\n",
       "      <td>2792300</td>\n",
       "      <td>12127600</td>\n",
       "      <td>6776300</td>\n",
       "      <td>2735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>55.382324</td>\n",
       "      <td>55.209000</td>\n",
       "      <td>31.274883</td>\n",
       "      <td>22.206837</td>\n",
       "      <td>66.722588</td>\n",
       "      <td>104.125885</td>\n",
       "      <td>53.958111</td>\n",
       "      <td>29.316330</td>\n",
       "      <td>51.113644</td>\n",
       "      <td>...</td>\n",
       "      <td>2228100</td>\n",
       "      <td>36170200</td>\n",
       "      <td>46491300</td>\n",
       "      <td>9344300</td>\n",
       "      <td>9397400</td>\n",
       "      <td>7847300</td>\n",
       "      <td>5930700</td>\n",
       "      <td>15108000</td>\n",
       "      <td>7458600</td>\n",
       "      <td>2657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>56.025253</td>\n",
       "      <td>55.266296</td>\n",
       "      <td>30.890682</td>\n",
       "      <td>22.206837</td>\n",
       "      <td>67.259598</td>\n",
       "      <td>104.961121</td>\n",
       "      <td>54.388023</td>\n",
       "      <td>29.671158</td>\n",
       "      <td>51.901459</td>\n",
       "      <td>...</td>\n",
       "      <td>1528700</td>\n",
       "      <td>19621700</td>\n",
       "      <td>44437400</td>\n",
       "      <td>7620200</td>\n",
       "      <td>7514000</td>\n",
       "      <td>7022700</td>\n",
       "      <td>21831500</td>\n",
       "      <td>14847100</td>\n",
       "      <td>5648400</td>\n",
       "      <td>2660500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  XLB_Close  XLC_Close  XLE_Close  XLF_Close  XLI_Close  \\\n",
       "0 2020-07-16  54.920506  54.941647  30.416573  22.060677  66.268852   \n",
       "1 2020-07-17  55.382324  54.817520  29.991512  21.877981  66.667023   \n",
       "2 2020-07-20  54.902401  55.476357  29.492876  21.777494  65.852211   \n",
       "3 2020-07-21  55.382324  55.209000  31.274883  22.206837  66.722588   \n",
       "4 2020-07-22  56.025253  55.266296  30.890682  22.206837  67.259598   \n",
       "\n",
       "    XLK_Close  XLP_Close  XLRE_Close  XLU_Close  ...  XLC_Volume  XLE_Volume  \\\n",
       "0  102.061813  53.747543   29.181149  50.420036  ...     2216700    18822800   \n",
       "1  102.561005  54.037067   29.586670  51.558929  ...     1928900    17716900   \n",
       "2  105.181931  53.493111   29.307875  50.882427  ...     2205300    20076500   \n",
       "3  104.125885  53.958111   29.316330  51.113644  ...     2228100    36170200   \n",
       "4  104.961121  54.388023   29.671158  51.901459  ...     1528700    19621700   \n",
       "\n",
       "   XLF_Volume  XLI_Volume  XLK_Volume  XLP_Volume  XLRE_Volume  XLU_Volume  \\\n",
       "0    74678500    13017100     8590300     7770200      3339300    15063200   \n",
       "1    47033200     8605200     6355200     6321700      8696300    22950800   \n",
       "2    40127600     9404600     8509200     6818600      2792300    12127600   \n",
       "3    46491300     9344300     9397400     7847300      5930700    15108000   \n",
       "4    44437400     7620200     7514000     7022700     21831500    14847100   \n",
       "\n",
       "   XLV_Volume  XLY_Volume  \n",
       "0     6412200     3024700  \n",
       "1     7548600     3094600  \n",
       "2     6776300     2735800  \n",
       "3     7458600     2657900  \n",
       "4     5648400     2660500  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_sector_data(sector_mapping) -> pd.DataFrame:\n",
    "\n",
    "    start_date = (datetime.now() - timedelta(days=5 * 365)).strftime('%Y-%m-%d')\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"Downloading Sector-Based Data...\")\n",
    "    sector_data = yf.download(tickers=list(sector_mapping.keys()), start=start_date, end=end_date)\n",
    "    print(f\"Downloaded yfinance sector data for =:\\n-> Keys: {list(sector_mapping.keys())}\\n-> Values: list{sector_mapping.values()}\")\n",
    "\n",
    "    print(f\"Flattening Column Labels to Remove Tuple-Based Column Structure... & Shifting Date into Column\")\n",
    "    sector_data.columns = [f\"{sector}_{metric}\" for metric, sector in sector_data.columns]\n",
    "    sector_data = sector_data.reset_index()\n",
    "\n",
    "    print(f\"* Done Preprocessing and Organizing Data *\")\n",
    "    return sector_data\n",
    "\n",
    "sector_data = download_sector_data(sector_mapping=sector_mapping)\n",
    "sector_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6362d3",
   "metadata": {},
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b234ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Different Dataframes\n",
    "def get_sector_data_separated(sector_mapping, original_data, original_columns) -> dict:\n",
    "    sector_separated_data = {}\n",
    "\n",
    "    for sector in sector_mapping.keys():\n",
    "        sector_separated_data[sector] = original_data[[f\"{sector}_{metric[metric.index(\"_\") + 1:]}\" for metric in original_columns if sector in metric]].copy()\n",
    "        sector_data = sector_separated_data[sector] # Dynamic State any change conserved\n",
    "        new_columns = [old[old.index(\"_\") + 1:] for old in sector_data.columns if \"_\" in old]\n",
    "        sector_data.columns = new_columns\n",
    "        sector_data[\"Date\"] = original_data[\"Date\"].values\n",
    "        sector_data[\"Sector\"] = sector\n",
    "        sector_data[\"Liquidity\"] = sector_data[\"Volume\"] * sector_data[\"Close\"]\n",
    "\n",
    "        sector_data[\"IntraDay_Return($)\"] = sector_data[\"Close\"] - sector_data[\"Open\"]\n",
    "        sector_data[\"InterDay_Return($)\"] = sector_data[\"Close\"] - sector_data[\"Close\"].shift(1)\n",
    "\n",
    "        sector_data[\"IntraDay_Return(%)\"] = sector_data[\"IntraDay_Return($)\"] / sector_data[\"Open\"]\n",
    "        sector_data[\"InterDay_Return(%)\"] = sector_data[\"InterDay_Return($)\"] / sector_data[\"Close\"].shift(1)\n",
    "\n",
    "        for bound in [\"Intra\", \"Inter\"]:\n",
    "            sector_data[f\"{bound}_Gain\"] = np.max(sector_data[\"IntraDay_Return($)\"], 0)\n",
    "            sector_data[f\"{bound}_Loss\"] = np.max(-1 * sector_data[\"IntraDay_Return($)\"], 0)\n",
    "            sector_data[f\"Log_{bound}_Return(%)\"] = np.log(sector_data[f\"{bound}Day_Return(%)\"])\n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7267040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated Sector Data Keys: ['XLK', 'XLF', 'XLE', 'XLV', 'XLI', 'XLP', 'XLY', 'XLU', 'XLB', 'XLRE', 'XLC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\lordw\\OneDrive\\Documents\\ML\\MLprojects\\AlphaGrid\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sector_separated_data = get_sector_data_separated(sector_mapping=sector_mapping, original_data=sector_data, original_columns=sector_data.columns)\n",
    "print(f\"Separated Sector Data Keys: {list(sector_separated_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e1626",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb85e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sector_momentums(sector_separated_data, momentums) -> dict:\n",
    "    for sector in sector_separated_data.keys():\n",
    "        sector_data = sector_separated_data[sector] # Not using copy so it remains in a dynamic state\n",
    "\n",
    "        # Calcuting the separate momentums for specific \"sector\"\n",
    "        for momentum in momentums:\n",
    "            sector_data[f\"Opening_Momentum_{momentum}Days\"] = sector_data[\"Open\"] - sector_data[\"Open\"].shift(momentum)\n",
    "            sector_data[f\"Closing_Momentum_{momentum}Days\"] = sector_data[\"Close\"] - sector_data[\"Close\"].shift(momentum)\n",
    "            sector_data[f\"High_Momentum_{momentum}Days\"] = sector_data[\"High\"] - sector_data[\"High\"].shift(momentum)\n",
    "            sector_data[f\"Low_Momentum_{momentum}Days\"] = sector_data[\"Low\"] - sector_data[\"Low\"].shift(momentum)\n",
    "            sector_data[f\"Volume_Momentum_{momentum}Days\"] = sector_data[\"Volume\"] - sector_data[\"Volume\"].shift(momentum)\n",
    "            \n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfe419",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentums = [5, 10, 20, 30]\n",
    "sector_separated_data = calculate_sector_momentums(sector_separated_data=sector_separated_data, momentums=momentums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143d0e0",
   "metadata": {},
   "source": [
    "### Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a148ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualate_sector_moving_averages(sector_separated_data, moving_averages) -> dict:\n",
    "    for sector in sector_separated_data.keys():\n",
    "        sector_data = sector_separated_data[sector] # Not using copy so it remains in a dynamic state\n",
    "\n",
    "        # Calcuting the separate momentums for specific \"sector\"\n",
    "        for ma in moving_averages:\n",
    "            sector_data[f\"Opening_MovingAverage_{ma}Days\"] = sector_data[\"Open\"].rolling(window=ma).mean()\n",
    "            sector_data[f\"Closing_MovingAverage_{ma}Days\"] = sector_data[\"Close\"].rolling(window=ma).mean()\n",
    "            sector_data[f\"High_MovingAverage_{ma}Days\"] = sector_data[\"High\"].rolling(window=ma).mean()\n",
    "            sector_data[f\"Low_MovingAverage_{ma}Days\"] = sector_data[\"Low\"].rolling(window=ma).mean()\n",
    "            sector_data[f\"Volume_MovingAverage_{ma}Days\"] = sector_data[\"Volume\"].rolling(window=ma).mean()\n",
    "            \n",
    "        for bound in [\"Intra\", \"Inter\"]:\n",
    "            sector_data[f\"{bound}_Gain_MovingAverage_{14}Days\"] = sector_data[f\"{bound}_Gain\"].rolling(window=14).mean()\n",
    "            sector_data[f\"{bound}_Loss_MovingAverage_{14}Days\"] = sector_data[f\"{bound}_Loss\"].rolling(window=14).mean()\n",
    "                \n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc583d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_averages = [5, 10, 20, 30]\n",
    "sector_separated_data = calcualate_sector_moving_averages(sector_separated_data=sector_separated_data, moving_averages=moving_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b64a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Features: ['Close', 'High', 'Low', 'Open', 'Volume', 'Date', 'Sector', 'Liquidity', 'IntraDay_Return($)', 'InterDay_Return($)', 'IntraDay_Return(%)', 'InterDay_Return(%)', 'Intra_Gain', 'Intra_Loss', 'Log_Intra_Return(%)', 'Inter_Gain', 'Inter_Loss', 'Log_Inter_Return(%)', 'Opening_Momentum_5Days', 'Closing_Momentum_5Days', 'High_Momentum_5Days', 'Low_Momentum_5Days', 'Volume_Momentum_5Days', 'Opening_Momentum_10Days', 'Closing_Momentum_10Days', 'High_Momentum_10Days', 'Low_Momentum_10Days', 'Volume_Momentum_10Days', 'Opening_Momentum_20Days', 'Closing_Momentum_20Days', 'High_Momentum_20Days', 'Low_Momentum_20Days', 'Volume_Momentum_20Days', 'Opening_Momentum_30Days', 'Closing_Momentum_30Days', 'High_Momentum_30Days', 'Low_Momentum_30Days', 'Volume_Momentum_30Days', 'Opening_MovingAverage_5Days', 'Closing_MovingAverage_5Days', 'High_MovingAverage_5Days', 'Low_MovingAverage_5Days', 'Volume_MovingAverage_5Days', 'Opening_MovingAverage_10Days', 'Closing_MovingAverage_10Days', 'High_MovingAverage_10Days', 'Low_MovingAverage_10Days', 'Volume_MovingAverage_10Days', 'Opening_MovingAverage_20Days', 'Closing_MovingAverage_20Days', 'High_MovingAverage_20Days', 'Low_MovingAverage_20Days', 'Volume_MovingAverage_20Days', 'Opening_MovingAverage_30Days', 'Closing_MovingAverage_30Days', 'High_MovingAverage_30Days', 'Low_MovingAverage_30Days', 'Volume_MovingAverage_30Days', 'Intra_Gain_MovingAverage_14Days', 'Intra_Loss_MovingAverage_14Days', 'Inter_Gain_MovingAverage_14Days', 'Inter_Loss_MovingAverage_14Days']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current Features: {[i for i in sector_separated_data[\"XLB\"].columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3f4d7",
   "metadata": {},
   "source": [
    "### Relative Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f3bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sector_relative_strengths(sector_separated_data, rsi_periods=[14]) -> dict:\n",
    "    for sector in sector_separated_data.keys():\n",
    "        sector_data = sector_separated_data[sector] # Not using copy so it remains in a dynamic state\n",
    "\n",
    "        # Calcuting the separate momentums for specific \"sector\"\n",
    "        for prd in rsi_periods:\n",
    "            for bound in [\"Intra\", \"Inter\"]:    \n",
    "                sector_data[f\"{bound}_RSI_{prd}Days\"] = 100 - (100 / (1 + (sector_data[f\"{bound}_Gain_MovingAverage_{prd}Days\"] / sector_data[f\"{bound}_Loss_MovingAverage_{prd}Days\"])))\n",
    "\n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c323aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi_periods = [14]\n",
    "sector_separated_data = calculate_sector_relative_strengths(sector_separated_data=sector_separated_data, rsi_periods=rsi_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f4f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Features: {len(sector_separated_data[\"XLB\"].columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b92da2",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5681e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sector_realized_volatility(sector_separated_data, periods) -> dict:\n",
    "    \"\"\"\n",
    "    Inner Volatility DURING the day -> Intra Only\n",
    "    \"\"\"\n",
    "    for sector in sector_separated_data.keys():\n",
    "        sector_data = sector_separated_data[sector]\n",
    "\n",
    "        for prd in periods:\n",
    "            sector_data[f\"RV_{prd}Days\"] = (\n",
    "                sector_data[\"IntraDay_Return(%)\"]\n",
    "                .rolling(window=prd)\n",
    "                .apply(lambda x: np.sqrt(np.sum(x**2)), raw=True)\n",
    "            )\n",
    "            sector_data[f\"RV_{prd}Days_1DayDelta(%)\"] = (sector_data[f\"RV_{prd}Days\"] - sector_data[f\"RV_{prd}Days\"].shift(1)) / sector_data[f\"RV_{prd}Days\"].shift(1)\n",
    "\n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8726ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "realized_volatility_periods = [5, 10, 20, 30]\n",
    "sector_separated_data = calculate_sector_realized_volatility(sector_separated_data=sector_separated_data, periods=realized_volatility_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72a48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(sector_separated_data):\n",
    "    for sector in sector_separated_data.keys():\n",
    "        sector_data = sector_separated_data[sector]\n",
    "        sector_data = sector_data.dropna()\n",
    "\n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59d13252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_target(sector_separated_data):\n",
    "    for sector in sector_separated_data.keys():\n",
    "        sector_data = sector_separated_data[sector]\n",
    "        sector_data[\"Target\"] = sector_data[\"RV_5Days_1DayDelta(%)\"].shift(-1)\n",
    "\n",
    "    return sector_separated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33c930a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_separated_data = remove_nans(sector_separated_data)\n",
    "sector_separated_data = define_target(sector_separated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9424ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Data: 13794\n",
      "# of Features: 73\n",
      "Features:\n",
      "Close\n",
      "\n",
      "High|Low|Open|Volume|Date|Sector\n",
      "\n",
      "Liquidity|IntraDay_Return($)|InterDay_Return($)|IntraDay_Return(%)|InterDay_Return(%)|Intra_Gain\n",
      "\n",
      "Intra_Loss|Log_Intra_Return(%)|Inter_Gain|Inter_Loss|Log_Inter_Return(%)|Opening_Momentum_5Days\n",
      "\n",
      "Closing_Momentum_5Days|High_Momentum_5Days|Low_Momentum_5Days|Volume_Momentum_5Days|Opening_Momentum_10Days|Closing_Momentum_10Days\n",
      "\n",
      "High_Momentum_10Days|Low_Momentum_10Days|Volume_Momentum_10Days|Opening_Momentum_20Days|Closing_Momentum_20Days|High_Momentum_20Days\n",
      "\n",
      "Low_Momentum_20Days|Volume_Momentum_20Days|Opening_Momentum_30Days|Closing_Momentum_30Days|High_Momentum_30Days|Low_Momentum_30Days\n",
      "\n",
      "Volume_Momentum_30Days|Opening_MovingAverage_5Days|Closing_MovingAverage_5Days|High_MovingAverage_5Days|Low_MovingAverage_5Days|Volume_MovingAverage_5Days\n",
      "\n",
      "Opening_MovingAverage_10Days|Closing_MovingAverage_10Days|High_MovingAverage_10Days|Low_MovingAverage_10Days|Volume_MovingAverage_10Days|Opening_MovingAverage_20Days\n",
      "\n",
      "Closing_MovingAverage_20Days|High_MovingAverage_20Days|Low_MovingAverage_20Days|Volume_MovingAverage_20Days|Opening_MovingAverage_30Days|Closing_MovingAverage_30Days\n",
      "\n",
      "High_MovingAverage_30Days|Low_MovingAverage_30Days|Volume_MovingAverage_30Days|Intra_Gain_MovingAverage_14Days|Intra_Loss_MovingAverage_14Days|Inter_Gain_MovingAverage_14Days\n",
      "\n",
      "Inter_Loss_MovingAverage_14Days|Intra_RSI_14Days|Inter_RSI_14Days|RV_5Days|RV_5Days_1DayDelta(%)|RV_10Days\n",
      "\n",
      "RV_10Days_1DayDelta(%)|RV_20Days|RV_20Days_1DayDelta(%)|RV_30Days|RV_30Days_1DayDelta(%)|Target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length Data: {len(sector_separated_data[\"XLB\"]) * len(sector_separated_data.keys())}\")\n",
    "print(f\"# of Features: {len(sector_separated_data[\"XLB\"].columns)}\")\n",
    "\n",
    "print(f\"Features:\")\n",
    "for idx, i in enumerate(sector_separated_data[\"XLB\"].columns):\n",
    "    if idx % 6 != 0:\n",
    "        print(f\"{i}\", end=\"|\")\n",
    "    else:\n",
    "        print(f\"{i}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
